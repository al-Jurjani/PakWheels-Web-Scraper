{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just scraper.py in a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs4\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from typing import List\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# called by scrapePages()\n",
    "def findCars(soup = bs4) -> List[str]:\n",
    "    count = 0\n",
    "    listings = soup.find_all('li', class_ = \"classified-listing featured-listing managed-pw\") + soup.find_all('li', class_ = \"classified-listing featured-listing\") + soup.find_all('li', class_ = \"classified-listing\")\n",
    "    # I found three types of listings, perhaps they may be more types.\n",
    "\n",
    "    data = [\n",
    "        ['name', 'price', 'city', 'production_year', 'km_driven', 'engine_type', 'horsepower', 'transmission', 'link']\n",
    "    ]\n",
    "\n",
    "    for index, car in enumerate(listings):\n",
    "        name = car.find('a', class_ = \"car-name ad-detail-path\")['title']\n",
    "        link = car.find('a', class_ = \"car-name ad-detail-path\")['href']\n",
    "        price = car.find('div', class_ = \"price-details generic-dark-grey\").text.strip()\n",
    "        price = price.replace('PKR ', \"\")\n",
    "        price = price.replace('.', \"\")\n",
    "        if 'lacs' in price:\n",
    "            price = price.replace(' lacs', '00000')\n",
    "        elif 'crore' in price:\n",
    "            price = price.replace(' crore', '000000')\n",
    "        city = car.find('ul', class_ = \"list-unstyled search-vehicle-info fs13\").text.strip()\n",
    "        info = car.find('ul', class_ = \"list-unstyled search-vehicle-info-2 fs13\").text.strip()\n",
    "        bits = info.split(\"\\n\") # prod year, km_driven, engine_type, horsepower, transmission\n",
    "\n",
    "        tuple = ['', '', '', '', '', '', '', '', '']\n",
    "        tuple[0] = name\n",
    "        tuple[1] = price.replace(',', \"\")\n",
    "        tuple[2] =  city\n",
    "        tuple[3] =  bits[0]\n",
    "        tuple[4] =  bits[1].replace('km', \"\").replace(',', \"\").strip()\n",
    "        tuple[5] =  bits[2]\n",
    "        tuple[6] = bits[3].replace('cc', \"\")\n",
    "        tuple[7] =  bits[4]\n",
    "        tuple[8] =  'pakwheels.com' + link\n",
    "        data.append(tuple)\n",
    "        count += 1\n",
    "    print(\"Listings from Page Completed!\")\n",
    "    print(f\"Total cars in the Page: {count}\\n\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapePages(link = str) -> int:\n",
    "    url = link\n",
    "    total = 0\n",
    "    data = []\n",
    "\n",
    "    while True:\n",
    "        driver =  webdriver.Edge()\n",
    "        driver.get(url)\n",
    "        print(\"waiting for page to completely load.\")\n",
    "        time.sleep(10)\n",
    "\n",
    "        soup = bs4(driver.page_source, 'lxml')\n",
    "        next_page = soup.find('li', class_ = \"next_page\")\n",
    "        # print(next_page) # prints 'None' if no next_page\n",
    "        search = soup.find('div', class_ = \"used-car-search-results\").h1.text\n",
    "        data = findCars(soup)\n",
    "\n",
    "        if total == 0: # creating new file\n",
    "            with open(f'files/{search.replace(' ', '_')}.csv', mode = 'w', newline = '') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(data)\n",
    "        else: # file already exists, need to append it\n",
    "            with open(f'files/{search.replace(' ', '_')}.csv', mode = 'a', newline = '') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerows(data)\n",
    "\n",
    "        total += len(data)\n",
    "        if next_page == None:\n",
    "            print(\"No more listings available!\")\n",
    "            return total\n",
    "        else:\n",
    "            url = 'https://www.pakwheels.com' + next_page.a['href']\n",
    "            # print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 50\n",
      "\n",
      "\n",
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 73\n",
      "\n",
      "\n",
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 73\n",
      "\n",
      "\n",
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 74\n",
      "\n",
      "\n",
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 73\n",
      "\n",
      "\n",
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 74\n",
      "\n",
      "\n",
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 71\n",
      "\n",
      "\n",
      "waiting for page to completely load.\n",
      "Listings from Page Completed!\n",
      "Total cars in the Page: 35\n",
      "\n",
      "\n",
      "No more listings available!\n",
      "The total number of cars for your search criteria right now are: 530\n"
     ]
    }
   ],
   "source": [
    "total_cars = scrapePages('https://www.pakwheels.com/used-cars/search/-/ct_karachi/cert_pakwheels-certified/')\n",
    "print(f'The total number of cars for your search criteria right now are: {total_cars - 1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
